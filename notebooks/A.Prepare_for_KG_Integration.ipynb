{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "603c36f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import omeka_extractor as oe\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8c28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ou\n",
    "metadata_categories = ou.load_yaml('../metadata_categories.yaml')\n",
    "metadata_categories_global = ou.load_yaml('../metadata_categories_global.yaml')\n",
    "categories_metadata = ou.reverse_yaml(metadata_categories)\n",
    "categories_metadata_global = ou.reverse_yaml(metadata_categories_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "325ac2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('../data/metadata_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32e044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df[\"element__category\"] = metadata_df[\"element__name\"].map(categories_metadata)\n",
    "metadata_df[\"element__category__global\"] = metadata_df[\"element__name\"].map(categories_metadata_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3604fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_categorised = metadata_df[['id', 'item_type__name', 'element__name', 'element__category', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f771bf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "item_type__name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a34b0de2-44f4-4607-8a34-b0e1cdf14ba0",
       "rows": [
        [
         "Still Image",
         "287"
        ],
        [
         "Text Item",
         "111"
        ],
        [
         "Contextual Item",
         "104"
        ],
        [
         "Landscape Item",
         "92"
        ],
        [
         "Viewpoint",
         "54"
        ],
        [
         "Physical Object",
         "32"
        ],
        [
         "Biographical Text",
         "24"
        ],
        [
         "Exhibit Metadata",
         "16"
        ],
        [
         "Oral History",
         "15"
        ],
        [
         "Moving Image",
         "2"
        ],
        [
         "Sound",
         "2"
        ],
        [
         "Background Panel",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/plain": [
       "item_type__name\n",
       "Still Image          287\n",
       "Text Item            111\n",
       "Contextual Item      104\n",
       "Landscape Item        92\n",
       "Viewpoint             54\n",
       "Physical Object       32\n",
       "Biographical Text     24\n",
       "Exhibit Metadata      16\n",
       "Oral History          15\n",
       "Moving Image           2\n",
       "Sound                  2\n",
       "Background Panel       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Num of unique items per item type\n",
    "metadata_df[['id', 'item_type__name']].drop_duplicates()['item_type__name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af466a5",
   "metadata": {},
   "source": [
    "### Items with text metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "858394ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "omeka_text = metadata_categorised[metadata_categorised['element__category'] == \"Content Description (English)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be7ea6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_854232/4026513723.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  omeka_text['word_count'] = omeka_text['text'].str.split().apply(len)\n",
      "/tmp/ipykernel_854232/4026513723.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  omeka_text['text_length'] = omeka_text['text'].str.len()\n"
     ]
    }
   ],
   "source": [
    "# Count metadata length\n",
    "omeka_text['word_count'] = omeka_text['text'].str.split().apply(len)\n",
    "omeka_text['text_length'] = omeka_text['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5fffa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "omeka_text_filtered = omeka_text.loc[omeka_text.groupby('id')['text_length'].apply(lambda x: x.idxmax())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ccb370b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "item_type__name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d67d4916-a4d4-41f8-9026-848cf10eed64",
       "rows": [
        [
         "Still Image",
         "280"
        ],
        [
         "Text Item",
         "109"
        ],
        [
         "Contextual Item",
         "104"
        ],
        [
         "Landscape Item",
         "92"
        ],
        [
         "Physical Object",
         "30"
        ],
        [
         "Biographical Text",
         "22"
        ],
        [
         "Exhibit Metadata",
         "16"
        ],
        [
         "Oral History",
         "15"
        ],
        [
         "Moving Image",
         "1"
        ],
        [
         "Sound",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "item_type__name\n",
       "Still Image          280\n",
       "Text Item            109\n",
       "Contextual Item      104\n",
       "Landscape Item        92\n",
       "Physical Object       30\n",
       "Biographical Text     22\n",
       "Exhibit Metadata      16\n",
       "Oral History          15\n",
       "Moving Image           1\n",
       "Sound                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omeka_text_filtered['item_type__name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6558bb2",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "143bde7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image items: 280\n",
      "Number of image items with > 100 chars: 97\n"
     ]
    }
   ],
   "source": [
    "# How many items are images?\n",
    "omeka_images = omeka_text_filtered[omeka_text_filtered['item_type__name'] == 'Still Image']\n",
    "print(f\"Number of image items: {len(omeka_images)}\")\n",
    "\n",
    "# How many of these images have text descriptions with > 100 chars?\n",
    "omeka_images_100 = omeka_images[omeka_images['text_length'] > 100]\n",
    "print(f\"Number of image items with > 100 chars: {len(omeka_images_100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a18bd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text_length",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d771c894-1c2c-4abb-867d-aaee2034661f",
       "rows": [
        [
         "count",
         "280.0"
        ],
        [
         "mean",
         "108.48928571428571"
        ],
        [
         "std",
         "139.7616246068627"
        ],
        [
         "min",
         "11.0"
        ],
        [
         "25%",
         "21.0"
        ],
        [
         "50%",
         "49.5"
        ],
        [
         "75%",
         "144.0"
        ],
        [
         "max",
         "1130.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/plain": [
       "count     280.000000\n",
       "mean      108.489286\n",
       "std       139.761625\n",
       "min        11.000000\n",
       "25%        21.000000\n",
       "50%        49.500000\n",
       "75%       144.000000\n",
       "max      1130.000000\n",
       "Name: text_length, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omeka_images['text_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd51305",
   "metadata": {},
   "source": [
    "#### Text / Diaries ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e2ad086",
   "metadata": {},
   "outputs": [],
   "source": [
    "omeka_descriptions = omeka_text_filtered[omeka_text_filtered['item_type__name'].isin(['Contextual Item', 'Text Item'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2975b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text/diary items with > 100 chars: 206\n"
     ]
    }
   ],
   "source": [
    "# How many of these items have text descriptions with > 100 chars?\n",
    "omeka_descriptions_100 = omeka_descriptions[omeka_descriptions['text_length'] > 100]\n",
    "print(f\"Number of text/diary items with > 100 chars: {len(omeka_descriptions_100)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-cdss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
